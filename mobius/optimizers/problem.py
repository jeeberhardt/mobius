#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Problem
#

import numpy as np
from pymoo.core.problem import Problem


class Problem(Problem):
    """
    Class to define Single/Multi/Many-Objectives SequenceGA problem.
    """

    def __init__(self, polymers, scores, acq_fun, n_inequality_constr=0, n_equality_constr=0, **kwargs):
        """
        Initialize the Single/Multi/Many-Objectives SequenceGA problem.

        Parameters
        ----------
        acq_fun : `AcquisitionFunction`
            Acquisition function to be evaluated for each new polymer generated.
        n_inequality_constr : int, default : 0
            Number of inequality constraints.
        n_equality_constr : int, default : 0
            Number of equality constraints.
        **kwargs : dict
            Additional keyword arguments.

        """
        super().__init__(n_var=1, n_obj=acq_fun.number_of_objectives,
                         n_ieq_constr=n_inequality_constr,
                         n_eq_constr=n_equality_constr)

        self._prior_data = {p: s for p, s in zip(polymers, scores)}
        self._polymers_cache = {}
        self._acq_fun = acq_fun
        self._pre_evaluation = True

    def _evaluate(self, x, out, *args, **kwargs):
        """
        Function to evaluate performance of each new polymer generated.

        Parameters
        ----------
        x : ndarray of str
            Polymers generated by GA to be evaluated by the acquisition functions
        out : ndarray
            Returning objective functions' scores to be minimised by pymoo.

        """
        polymers = x.ravel()
        pre_evaluation_penalty = 999.

        if self._pre_evaluation:
            # For the first GA generation, we use the experimental scores
            # then we will use the acquisition scores from the surrogate models.
            try:
                # We shift all the experimental scores in the opposite direction
                # by a large number to ensure that the polymers generated during the
                # optimization will be better acquisition scores.
                acq_values = np.array([self._prior_data[p] for p in polymers])
                acq_values += -1. * self._acq_fun.scaling_factors * pre_evaluation_penalty
            except KeyError:
                msg = f'Some polymers not found in the input experimental data. '
                msg += 'Did you forget to turn on the eval mode?'
                raise RuntimeError(msg)
        else:
            # Evaluate unseen polymer with acquisition scores from surrogate models
            acq_values = self._acq_fun.forward(polymers) * self._acq_fun.scaling_factors

        out["F"] = acq_values

    def pre_eval(self):
        """
        Function to set pre-evaluation mode on. In pre-evaluation mode, the scores will be
        obtained from the experimental data only.

        """
        self._pre_evaluation = True

    def eval(self):
        """
        Function to set pre-evaluation mode off. In evaluation mode, the scores will be
        obtained from the surrogate models.

        """
        self._pre_evaluation = False

#!/usr/bin/env python
# -*- coding: utf-8 -*-
#
# Problem
#

import numpy as np
from pymoo.core.problem import Problem


class Problem(Problem):
    """
    Class to define Single/Multi/Many-Objectives SequenceGA problem.
    """

    def __init__(self, polymers, scores, acq_funs, n_inequality_constr=0, n_equality_constr=0, **kwargs):
        """
        Initialize the Single/Multi/Many-Objectives SequenceGA problem.

        Parameters
        ----------
        acq_funs : `AcquisitionFunction` or list of `AcquisitionFunction` objects
            Acquisition functions to be evaluated for each new polymer generated.
        n_inequality_constr : int, default : 0
            Number of inequality constraints.
        n_equality_constr : int, default : 0
            Number of equality constraints.
        **kwargs : dict
            Additional keyword arguments.

        """
        super().__init__(n_var=1, n_obj=len(acq_funs),
                         n_ieq_constr=n_inequality_constr,
                         n_eq_constr=n_equality_constr)

        self._prior_data = {p: s for p, s in zip(polymers, scores)}
        self._polymers_cache = {}
        if not isinstance(acq_funs, list):
            acq_funs = [acq_funs]
        self._acq_funs = acq_funs
        self._pre_evaluation = True

    def _evaluate(self, x, out, *args, **kwargs):
        """
        Function to evaluate performance of each new polymer generated.

        Parameters
        ----------
        x : ndarray of str
            Polymers generated by GA to be evaluated by the acquisition functions
        out : ndarray
            Returning objective functions' scores to be minimised by pymoo.

        """
        polymers = x.ravel()
        scores = np.zeros((len(polymers), len(self._acq_funs)))

        for i, acq_fun in enumerate(self._acq_funs):
            if self._pre_evaluation:
                # For the first GA generation, we use the experimental scores
                # then we will use the acquisition scores from the surrogate models.
                try:
                    # We shift all the experimental scores in the opposite direction
                    # by a large number to ensure that the polymers generated during the
                    # optimization will be better acquisition scores.
                    acq_values = np.array([self._prior_data[p][i] for p in polymers]) + (-acq_fun.scaling_factor * 999.)
                except KeyError:
                    msg = f'Some polymers not found in the input experimental data. '
                    msg += 'Did you forget to turn on the eval mode?'
                    raise RuntimeError(msg)
            else:
                # Evaluate unseen polymer with acquisition scores from surrogate models
                predictions = acq_fun.forward(polymers)
                acq_values = acq_fun.scaling_factor * predictions.acq

            scores[:, i] = acq_values

        out["F"] = scores

    def pre_eval(self):
        """
        Function to set pre-evaluation mode on. In pre-evaluation mode, the scores will be
        obtained from the experimental data only.

        """
        self._pre_evaluation = True

    def eval(self):
        """
        Function to set pre-evaluation mode off. In evaluation mode, the scores will be
        obtained from the surrogate models.

        """
        self._pre_evaluation = False
